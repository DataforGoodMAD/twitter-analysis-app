{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import spacy\n",
    "import es_core_news_md\n",
    "import es_core_news_sm\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "#Environment Variables\n",
    "consumer_key = os.environ.get('CONSUMER_KEY')\n",
    "consumer_secret = os.environ.get('CONSUMER_SECRET_KEY')\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_handled(cursor):\n",
    "    while True:\n",
    "        try:\n",
    "            yield cursor.next()\n",
    "        except tweepy.RateLimitError as e:\n",
    "            print(e)\n",
    "            print('Waiting for 15 minutes to continue making requests')\n",
    "            time.sleep(15 * 60)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-64d0121bb013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#User Timeline to a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_timeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"helsinkiespana\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'extended'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_rts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_replies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtweets_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "#User Timeline to a DataFrame\n",
    "tweets = tweepy.Cursor(api.user_timeline, id=\"helsinkiespana\", tweet_mode='extended', include_rts=False, exclude_replies=True).items()\n",
    "tweets_lst = [tweet._json for tweet in tweets]\n",
    "df_tweets = pd.DataFrame(tweets_lst)\n",
    "\n",
    "df_tweets.to_csv(f'./output/timeline_helsinkiespana.csv', index=False)\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>n_hashtag</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>lemmas_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1243156489956732930</td>\n",
       "      <td>HelsinkiEspa単a</td>\n",
       "      <td>7</td>\n",
       "      <td>HelsinkiEspa単a</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243156489956732930</td>\n",
       "      <td>ddhh</td>\n",
       "      <td>2</td>\n",
       "      <td>ddhh</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243156489956732930</td>\n",
       "      <td>JovenesparaJovenes</td>\n",
       "      <td>2</td>\n",
       "      <td>JovenesparaJovenes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243156489956732930</td>\n",
       "      <td>malaga</td>\n",
       "      <td>3</td>\n",
       "      <td>malaga</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1243156489956732930</td>\n",
       "      <td>oviedo</td>\n",
       "      <td>2</td>\n",
       "      <td>oviedo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id            hashtags  n_hashtag              lemmas  \\\n",
       "0  1243156489956732930      HelsinkiEspa単a          7      HelsinkiEspa単a   \n",
       "1  1243156489956732930                ddhh          2                ddhh   \n",
       "2  1243156489956732930  JovenesparaJovenes          2  JovenesparaJovenes   \n",
       "3  1243156489956732930              malaga          3              malaga   \n",
       "4  1243156489956732930              oviedo          2              oviedo   \n",
       "\n",
       "   lemmas_count  \n",
       "0             7  \n",
       "1             2  \n",
       "2             2  \n",
       "3             3  \n",
       "4             2  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#User Hashtags DataFrame\n",
    "hashtags = [[hashtag['text'] \n",
    "                    for hashtag in hashtags['hashtags']] \n",
    "                    for hashtags in df['entities']]\n",
    "\n",
    "df_hashtags = pd.DataFrame({\n",
    "    'id':np.repeat(df['id'].values, df['hashtags'].str.len()),\n",
    "    'hashtags':np.concatenate(df['hashtags'].values)\n",
    "})\n",
    "hashtags_count = df_hashtags['hashtags'].value_counts().to_dict()\n",
    "df_hashtags['n_hashtag'] = df_hashtags['hashtags'].map(hashtags_count)\n",
    "\n",
    "#Adding Lemmatisation\n",
    "lemm = spacy.blank('es')\n",
    "df_hashtags['lemmas'] = [lemm(lemma).text for lemma in df_hashtags['hashtags']]\n",
    "lemmas_count = df_hashtags['lemmas'].value_counts().to_dict()\n",
    "df_hashtags['lemmas_count'] = df_hashtags['lemmas'].map(lemmas_count)\n",
    "\n",
    "df_hashtags.to_csv('./output/hashtags_helsinkiespana.csv', index=False)\n",
    "df_hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Followers DataFrame\n",
    "def requestFollowers(username, )\n",
    "followers = tweepy.Cursor(api.followers, id=\"helsinkiespana\", count=200).items()\n",
    "followers_lst = [follower._json for follower in followers]\n",
    "df_followers = pd.DataFrame(followers_lst)\n",
    "df_followers.to_csv(f'./output/followers_helsinkiespana.csv', index=False)\n",
    "df_followers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search\n",
    "tweets = tweepy.Cursor(api.search,  \n",
    "                       tweet_mode='extended', \n",
    "                       q=\"\"\"\n",
    "                     derechoshumanos OR madrid OR gratis OR empleo OR humanrightsday OR reactcourse OR jovenesparajovenes OR humanrights OR humandimensionday OR react OR webinarsrio14 OR penademuerte OR ddhh OR caminodesantiago OR soles4globalgoals OR ciudadaniaue OR peacekeeping OR laeuropadelosjovenes OR crimenorganizado OR seguridadhumana OR #derechoshumanos OR #madrid OR #gratis OR #empleo OR #humanrightsday OR #reactcourse OR #jovenesparajovenes OR #humanrights OR #humandimensionday OR #react OR #webinarsrio14 OR #penademuerte OR #ddhh OR #caminodesantiago OR #soles4globalgoals OR #ciudadaniaue OR #peacekeeping OR #laeuropadelosjovenes OR #crimenorganizado OR #seguridadhumana\n",
    "                     \"\"\",\n",
    "                       result_type='recent',\n",
    "                      ).items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_words = [set(re.findall(r'#\\w*', unicodedata.normalize(\n",
    "            'NFKD', e.full_text).encode('ASCII', 'ignore').decode('utf-8').lower())) for e in search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[set(),\n",
       " {'#__', '#humanrights', '#notoexecution', '#taheri_moveme'},\n",
       " set(),\n",
       " {'#',\n",
       "  '#canadian',\n",
       "  '#citizens',\n",
       "  '#humanrights',\n",
       "  '#illegals',\n",
       "  '#legal',\n",
       "  '#porters',\n",
       "  '#rcmp',\n",
       "  '#roxhamroad',\n",
       "  '#stripped'},\n",
       " set(),\n",
       " {'#covid19', '#madrid'},\n",
       " {'#empleo'},\n",
       " set(),\n",
       " {'#20minutos', '#madrid'},\n",
       " {'#ddhh'},\n",
       " set(),\n",
       " set(),\n",
       " {'#react', '#youtube', '#youtubersreact'},\n",
       " {'#biodiversidad'},\n",
       " {'#__', '#humanrights', '#notoexecution', '#taheri_moveme'},\n",
       " set(),\n",
       " {'#carceldeguanare', '#derechoshumanos', '#ong'},\n",
       " {'#chihuahua', '#elalamo', '#madrid', '#perdida'},\n",
       " {'#empleo', '#felizlunes', '#reclutamiento', '#rrhh'},\n",
       " {'#humanrights'},\n",
       " {'#empleo', '#it', '#java', '#madrid', '#tic'},\n",
       " set(),\n",
       " set(),\n",
       " {'#farmacias', '#madrid', '#policia', '#sanse'},\n",
       " {'#react', '#youtube', '#youtubersreact'},\n",
       " {'#100daysofcode',\n",
       "  '#angular',\n",
       "  '#developers',\n",
       "  '#frontend',\n",
       "  '#javascript',\n",
       "  '#react'},\n",
       " {'#react', '#youtube', '#youtubersreact'},\n",
       " {'#adopci', '#madrid'},\n",
       " {'#gratis', '#pagina', '#web'},\n",
       " set(),\n",
       " {'#cumplecartasocial',\n",
       "  '#derechossocialessonderechoshumanos',\n",
       "  '#madrid',\n",
       "  '#marchabasica',\n",
       "  '#nadiepordebajodelumbraldepobreza'},\n",
       " {'#chihuahua', '#elalamo', '#madrid', '#perdida'},\n",
       " {'#farmacias', '#madrid', '#policia', '#sanse'},\n",
       " {'#madrid'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {'#covid19',\n",
       "  '#emprendimiento',\n",
       "  '#gratis',\n",
       "  '#ilab',\n",
       "  '#innovacion',\n",
       "  '#oportunidades',\n",
       "  '#reskilling',\n",
       "  '#webinar'},\n",
       " {'#cdnpoli', '#china', '#hongkongprotests', '#humanrights'},\n",
       " {'#alcorcon', '#madrid'},\n",
       " set(),\n",
       " {'#ddhh'},\n",
       " set(),\n",
       " {'#humanrights'},\n",
       " set(),\n",
       " {'#cdnpoli', '#china', '#hongkongprotests', '#humanrights'},\n",
       " set(),\n",
       " {'#adopci', '#madrid'},\n",
       " set(),\n",
       " {'#empleo'}]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hashtags = ['#derechoshumanos',\n",
    " '#madrid',\n",
    " '#gratis',\n",
    " '#empleo',\n",
    " '#humanrightsday',\n",
    " '#reactcourse',\n",
    " '#jovenesparajovenes',\n",
    " '#humanrights',\n",
    " '#humandimensionday',\n",
    " '#react',\n",
    " '#webinarsrio14',\n",
    " '#penademuerte',\n",
    " '#ddhh',\n",
    " '#caminodesantiago',\n",
    " '#soles4globalgoals',\n",
    " '#ciudadaniaue',\n",
    " '#peacekeeping',\n",
    " '#laeuropadelosjovenes',\n",
    " '#crimenorganizado',\n",
    " '#seguridadhumana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hashtags = [e[1:] for e in top_hashtags] + top_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'derechoshumanos OR madrid OR gratis OR empleo OR humanrightsday OR reactcourse OR jovenesparajovenes OR humanrights OR humandimensionday OR react OR webinarsrio14 OR penademuerte OR ddhh OR caminodesantiago OR soles4globalgoals OR ciudadaniaue OR peacekeeping OR laeuropadelosjovenes OR crimenorganizado OR seguridadhumana OR #derechoshumanos OR #madrid OR #gratis OR #empleo OR #humanrightsday OR #reactcourse OR #jovenesparajovenes OR #humanrights OR #humandimensionday OR #react OR #webinarsrio14 OR #penademuerte OR #ddhh OR #caminodesantiago OR #soles4globalgoals OR #ciudadaniaue OR #peacekeeping OR #laeuropadelosjovenes OR #crimenorganizado OR #seguridadhumana'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" OR \".join(top_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{'#humanrights'}\n",
      "set()\n",
      "{'#humanrights'}\n",
      "set()\n",
      "{'#madrid'}\n",
      "{'#empleo'}\n",
      "set()\n",
      "{'#madrid'}\n",
      "{'#ddhh'}\n",
      "set()\n",
      "set()\n",
      "{'#react'}\n",
      "set()\n",
      "{'#humanrights'}\n",
      "set()\n",
      "{'#derechoshumanos'}\n",
      "{'#madrid'}\n",
      "{'#empleo'}\n",
      "{'#humanrights'}\n",
      "{'#madrid', '#empleo'}\n",
      "set()\n",
      "set()\n",
      "{'#madrid'}\n",
      "{'#react'}\n",
      "{'#react'}\n",
      "{'#react'}\n",
      "{'#madrid'}\n",
      "{'#gratis'}\n",
      "set()\n",
      "{'#madrid'}\n",
      "{'#madrid'}\n",
      "{'#madrid'}\n",
      "{'#madrid'}\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{'#gratis'}\n",
      "{'#humanrights'}\n",
      "{'#madrid'}\n",
      "set()\n",
      "{'#ddhh'}\n",
      "set()\n",
      "{'#humanrights'}\n",
      "set()\n",
      "{'#humanrights'}\n",
      "set()\n",
      "{'#madrid'}\n",
      "set()\n",
      "{'#empleo'}\n"
     ]
    }
   ],
   "source": [
    "for e in set_words:\n",
    "    intersect = e.intersection(top_hashtags)\n",
    "    print(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#derechoshumanos'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
